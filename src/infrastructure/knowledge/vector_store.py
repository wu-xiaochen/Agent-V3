"""
å‘é‡å­˜å‚¨æ¥å£

æ”¯æŒå¤šç§å‘é‡æ•°æ®åº“åç«¯ï¼š
- ChromaDB (é»˜è®¤ï¼Œè½»é‡çº§ï¼Œæ— éœ€é¢å¤–æœåŠ¡)
- FAISS (Facebook AIï¼Œé«˜æ€§èƒ½)
- Pinecone (äº‘æœåŠ¡)
"""

import logging
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)


class VectorStore(ABC):
    """å‘é‡å­˜å‚¨æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    def add_documents(
        self,
        documents: List[str],
        metadatas: Optional[List[Dict[str, Any]]] = None,
        ids: Optional[List[str]] = None
    ) -> List[str]:
        """æ·»åŠ æ–‡æ¡£"""
        pass
    
    @abstractmethod
    def search(
        self,
        query: str,
        top_k: int = 5,
        filter_dict: Optional[Dict[str, Any]] = None
    ) -> List[Tuple[str, float, Dict[str, Any]]]:
        """æœç´¢æ–‡æ¡£"""
        pass
    
    @abstractmethod
    def delete_documents(self, ids: List[str]) -> bool:
        """åˆ é™¤æ–‡æ¡£"""
        pass
    
    @abstractmethod
    def get_document_count(self) -> int:
        """è·å–æ–‡æ¡£æ•°é‡"""
        pass


class ChromaDBStore(VectorStore):
    """
    ChromaDB å‘é‡å­˜å‚¨
    
    ä¼˜ç‚¹ï¼š
    - è½»é‡çº§ï¼Œæ— éœ€é¢å¤–æœåŠ¡
    - æ˜“äºéƒ¨ç½²
    - æ”¯æŒæœ¬åœ°å’Œè¿œç¨‹æ¨¡å¼
    """
    
    def __init__(
        self,
        collection_name: str,
        persist_directory: str,
        embedding_function: Optional[Any] = None
    ):
        """
        åˆå§‹åŒ– ChromaDB å­˜å‚¨
        
        Args:
            collection_name: é›†åˆåç§°
            persist_directory: æŒä¹…åŒ–ç›®å½•
            embedding_function: åµŒå…¥å‡½æ•°
        """
        try:
            import chromadb
            from chromadb.config import Settings
        except ImportError:
            raise ImportError(
                "ChromaDB æœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install chromadb"
            )
        
        self.collection_name = collection_name
        self.persist_directory = Path(persist_directory)
        self.persist_directory.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºå®¢æˆ·ç«¯
        self.client = chromadb.Client(Settings(
            chroma_db_impl="duckdb+parquet",
            persist_directory=str(self.persist_directory)
        ))
        
        # åˆ›å»ºæˆ–è·å–é›†åˆ
        self.collection = self.client.get_or_create_collection(
            name=collection_name,
            embedding_function=embedding_function
        )
        
        logger.info(f"âœ… ChromaDB å­˜å‚¨å·²åˆå§‹åŒ–: {collection_name}")
    
    def add_documents(
        self,
        documents: List[str],
        metadatas: Optional[List[Dict[str, Any]]] = None,
        ids: Optional[List[str]] = None
    ) -> List[str]:
        """æ·»åŠ æ–‡æ¡£åˆ°å‘é‡å­˜å‚¨"""
        try:
            # ç”ŸæˆIDï¼ˆå¦‚æœæœªæä¾›ï¼‰
            if ids is None:
                import uuid
                ids = [str(uuid.uuid4()) for _ in documents]
            
            # æ·»åŠ æ–‡æ¡£
            self.collection.add(
                documents=documents,
                metadatas=metadatas,
                ids=ids
            )
            
            logger.info(f"âœ… æ·»åŠ  {len(documents)} ä¸ªæ–‡æ¡£åˆ° ChromaDB")
            return ids
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ æ–‡æ¡£å¤±è´¥: {e}")
            raise
    
    def search(
        self,
        query: str,
        top_k: int = 5,
        filter_dict: Optional[Dict[str, Any]] = None
    ) -> List[Tuple[str, float, Dict[str, Any]]]:
        """æœç´¢ç›¸ä¼¼æ–‡æ¡£"""
        try:
            results = self.collection.query(
                query_texts=[query],
                n_results=top_k,
                where=filter_dict
            )
            
            # æ ¼å¼åŒ–ç»“æœ
            formatted_results = []
            if results["documents"] and results["documents"][0]:
                for i in range(len(results["documents"][0])):
                    doc = results["documents"][0][i]
                    distance = results["distances"][0][i] if "distances" in results else 0.0
                    metadata = results["metadatas"][0][i] if "metadatas" in results else {}
                    
                    formatted_results.append((doc, distance, metadata))
            
            return formatted_results
            
        except Exception as e:
            logger.error(f"âŒ æœç´¢æ–‡æ¡£å¤±è´¥: {e}")
            raise
    
    def delete_documents(self, ids: List[str]) -> bool:
        """åˆ é™¤æ–‡æ¡£"""
        try:
            self.collection.delete(ids=ids)
            logger.info(f"ğŸ—‘ï¸  åˆ é™¤ {len(ids)} ä¸ªæ–‡æ¡£")
            return True
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤æ–‡æ¡£å¤±è´¥: {e}")
            return False
    
    def get_document_count(self) -> int:
        """è·å–æ–‡æ¡£æ•°é‡"""
        try:
            return self.collection.count()
        except Exception as e:
            logger.error(f"âŒ è·å–æ–‡æ¡£æ•°é‡å¤±è´¥: {e}")
            return 0


class FAISSStore(VectorStore):
    """
    FAISS å‘é‡å­˜å‚¨
    
    ä¼˜ç‚¹ï¼š
    - é«˜æ€§èƒ½
    - é€‚åˆå¤§è§„æ¨¡æ•°æ®
    - Facebook AI å‡ºå“
    """
    
    def __init__(
        self,
        index_path: str,
        embedding_dim: int = 768,
        embedding_function: Optional[Any] = None
    ):
        """
        åˆå§‹åŒ– FAISS å­˜å‚¨
        
        Args:
            index_path: ç´¢å¼•æ–‡ä»¶è·¯å¾„
            embedding_dim: åµŒå…¥ç»´åº¦
            embedding_function: åµŒå…¥å‡½æ•°
        """
        try:
            import faiss
            import numpy as np
        except ImportError:
            raise ImportError(
                "FAISS æœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install faiss-cpu æˆ– pip install faiss-gpu"
            )
        
        self.index_path = Path(index_path)
        self.index_path.parent.mkdir(parents=True, exist_ok=True)
        self.embedding_dim = embedding_dim
        self.embedding_function = embedding_function
        
        # åˆ›å»ºæˆ–åŠ è½½ç´¢å¼•
        if self.index_path.exists():
            self.index = faiss.read_index(str(self.index_path))
            logger.info(f"âœ… åŠ è½½ FAISS ç´¢å¼•: {index_path}")
        else:
            self.index = faiss.IndexFlatL2(embedding_dim)
            logger.info(f"âœ… åˆ›å»º FAISS ç´¢å¼•: {index_path}")
        
        # æ–‡æ¡£å­˜å‚¨ï¼ˆID -> æ–‡æ¡£å†…å®¹å’Œå…ƒæ•°æ®ï¼‰
        self.documents = {}
        self.doc_id_to_index = {}  # doc_id -> index_position
    
    def add_documents(
        self,
        documents: List[str],
        metadatas: Optional[List[Dict[str, Any]]] = None,
        ids: Optional[List[str]] = None
    ) -> List[str]:
        """æ·»åŠ æ–‡æ¡£åˆ°å‘é‡å­˜å‚¨"""
        try:
            import numpy as np
            import uuid
            
            # ç”ŸæˆID
            if ids is None:
                ids = [str(uuid.uuid4()) for _ in documents]
            
            # ç”ŸæˆåµŒå…¥
            if self.embedding_function is None:
                raise ValueError("éœ€è¦æä¾› embedding_function")
            
            embeddings = []
            for doc in documents:
                embedding = self.embedding_function(doc)
                embeddings.append(embedding)
            
            embeddings_array = np.array(embeddings).astype('float32')
            
            # æ·»åŠ åˆ°ç´¢å¼•
            start_index = self.index.ntotal
            self.index.add(embeddings_array)
            
            # ä¿å­˜æ–‡æ¡£ä¿¡æ¯
            for i, doc_id in enumerate(ids):
                self.documents[doc_id] = {
                    "content": documents[i],
                    "metadata": metadatas[i] if metadatas else {}
                }
                self.doc_id_to_index[doc_id] = start_index + i
            
            # ä¿å­˜ç´¢å¼•
            import faiss
            faiss.write_index(self.index, str(self.index_path))
            
            logger.info(f"âœ… æ·»åŠ  {len(documents)} ä¸ªæ–‡æ¡£åˆ° FAISS")
            return ids
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ æ–‡æ¡£å¤±è´¥: {e}")
            raise
    
    def search(
        self,
        query: str,
        top_k: int = 5,
        filter_dict: Optional[Dict[str, Any]] = None
    ) -> List[Tuple[str, float, Dict[str, Any]]]:
        """æœç´¢ç›¸ä¼¼æ–‡æ¡£"""
        try:
            import numpy as np
            
            # ç”ŸæˆæŸ¥è¯¢åµŒå…¥
            if self.embedding_function is None:
                raise ValueError("éœ€è¦æä¾› embedding_function")
            
            query_embedding = self.embedding_function(query)
            query_array = np.array([query_embedding]).astype('float32')
            
            # æœç´¢
            distances, indices = self.index.search(query_array, top_k)
            
            # æ ¼å¼åŒ–ç»“æœ
            results = []
            for i, idx in enumerate(indices[0]):
                if idx == -1:  # FAISS è¿”å› -1 è¡¨ç¤ºæ²¡æœ‰æ‰¾åˆ°
                    continue
                
                # æŸ¥æ‰¾å¯¹åº”çš„æ–‡æ¡£ID
                doc_id = None
                for did, index_pos in self.doc_id_to_index.items():
                    if index_pos == idx:
                        doc_id = did
                        break
                
                if doc_id and doc_id in self.documents:
                    doc_info = self.documents[doc_id]
                    results.append((
                        doc_info["content"],
                        float(distances[0][i]),
                        doc_info["metadata"]
                    ))
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ æœç´¢æ–‡æ¡£å¤±è´¥: {e}")
            raise
    
    def delete_documents(self, ids: List[str]) -> bool:
        """åˆ é™¤æ–‡æ¡£"""
        # FAISS ä¸æ”¯æŒç›´æ¥åˆ é™¤ï¼Œéœ€è¦é‡å»ºç´¢å¼•
        logger.warning("âš ï¸  FAISS ä¸æ”¯æŒç›´æ¥åˆ é™¤æ–‡æ¡£ï¼Œéœ€è¦é‡å»ºç´¢å¼•")
        return False
    
    def get_document_count(self) -> int:
        """è·å–æ–‡æ¡£æ•°é‡"""
        return self.index.ntotal


def create_vector_store(
    backend: str,
    collection_name: str,
    persist_directory: str,
    embedding_function: Optional[Any] = None,
    **kwargs
) -> VectorStore:
    """
    åˆ›å»ºå‘é‡å­˜å‚¨å®ä¾‹
    
    Args:
        backend: åç«¯ç±»å‹ (chromadb, faiss)
        collection_name: é›†åˆåç§°
        persist_directory: æŒä¹…åŒ–ç›®å½•
        embedding_function: åµŒå…¥å‡½æ•°
        **kwargs: å…¶ä»–å‚æ•°
        
    Returns:
        å‘é‡å­˜å‚¨å®ä¾‹
    """
    if backend.lower() == "chromadb":
        return ChromaDBStore(
            collection_name=collection_name,
            persist_directory=persist_directory,
            embedding_function=embedding_function
        )
    elif backend.lower() == "faiss":
        index_path = Path(persist_directory) / f"{collection_name}.faiss"
        return FAISSStore(
            index_path=str(index_path),
            embedding_dim=kwargs.get("embedding_dim", 768),
            embedding_function=embedding_function
        )
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„å‘é‡å­˜å‚¨åç«¯: {backend}")

