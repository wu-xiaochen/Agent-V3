"""
LLMå·¥å‚ç±»
ç”¨äºåˆ›å»ºä¸åŒæä¾›å•†çš„LLMå®ä¾‹
"""

import warnings
import os
# åœ¨å¯¼å…¥LangChainä¹‹å‰è®¾ç½®ç¯å¢ƒå˜é‡æ¥æŠ‘åˆ¶å¼ƒç”¨è­¦å‘Š
os.environ["PYTHONWARNINGS"] = "ignore::DeprecationWarning:langchain.*"
warnings.filterwarnings("ignore", category=DeprecationWarning, module="langchain.*")

from typing import Dict, Any, Optional
from langchain_openai import OpenAI
from langchain_community.chat_models import ChatOpenAI
from langchain_community.llms import HuggingFaceHub
from langchain_community.chat_models import ChatAnthropic
from src.config.config_loader import config_loader


class LLMFactory:
    """LLMå·¥å‚ç±»"""
    
    @staticmethod
    def create_llm(provider: Optional[str] = None, **kwargs) -> Any:
        """
        åˆ›å»ºLLMå®ä¾‹
        
        Args:
            provider: LLMæä¾›å•†ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤æä¾›å•†
            **kwargs: é¢å¤–çš„LLMå‚æ•°
            
        Returns:
            LLMå®ä¾‹
        """
        if provider is None:
            # è·å–æœåŠ¡é…ç½®ä¸­çš„é»˜è®¤æä¾›å•†
            services_config = config_loader.get_services_config()
            services = services_config.get("services", {})
            llm_config = services.get("llm", {})
            provider = llm_config.get("provider", "openai")
        
        llm_config = config_loader.get_llm_config(provider)
        
        # åˆå¹¶å‚æ•°
        merged_config = {**llm_config, **kwargs}
        
        # æ ¹æ®æä¾›å•†åˆ›å»ºå¯¹åº”çš„LLMå®ä¾‹
        if provider == "openai":
            return LLMFactory._create_openai_llm(merged_config)
        elif provider == "anthropic":
            return LLMFactory._create_anthropic_llm(merged_config)
        elif provider == "huggingface":
            return LLMFactory._create_huggingface_llm(merged_config)
        elif provider == "siliconflow":
            return LLMFactory._create_siliconflow_llm(merged_config)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„LLMæä¾›å•†: {provider}")
    
    @staticmethod
    def _create_openai_llm(config: Dict[str, Any]) -> Any:
        """
        åˆ›å»ºOpenAI LLMå®ä¾‹
        
        Args:
            config: OpenAIé…ç½®
            
        Returns:
            OpenAI LLMå®ä¾‹
        """
        # ğŸ†• ä¼˜å…ˆä½¿ç”¨ EnvManager
        from src.config.env_manager import EnvManager
        api_key = config.get("api_key") or EnvManager.OPENAI_API_KEY
        if not api_key:
            raise ValueError("æœªæ‰¾åˆ°OpenAI APIå¯†é’¥ï¼Œè¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®æˆ–è®¾ç½®ç¯å¢ƒå˜é‡OPENAI_API_KEY")
        
        model = config.get("model") or EnvManager.get("OPENAI_DEFAULT_MODEL", "gpt-3.5-turbo")
        base_url = config.get("base_url") or EnvManager.OPENAI_BASE_URL
        
        # æ ¹æ®æ¨¡å‹ç±»å‹å†³å®šä½¿ç”¨ChatOpenAIè¿˜æ˜¯OpenAI
        if "gpt-" in model:
            return ChatOpenAI(
                openai_api_key=api_key,
                model_name=model,
                temperature=config.get("temperature", 0.7),
                max_tokens=config.get("max_tokens", 1000),
                top_p=config.get("top_p", 1.0),
                frequency_penalty=config.get("frequency_penalty", 0.0),
                presence_penalty=config.get("presence_penalty", 0.0),
                openai_api_base=base_url
            )
        else:
            return OpenAI(
                openai_api_key=api_key,
                model_name=model,
                temperature=config.get("temperature", 0.7),
                max_tokens=config.get("max_tokens", 1000),
                top_p=config.get("top_p", 1.0),
                frequency_penalty=config.get("frequency_penalty", 0.0),
                presence_penalty=config.get("presence_penalty", 0.0),
                openai_api_base=base_url
            )
    
    @staticmethod
    def _create_anthropic_llm(config: Dict[str, Any]) -> Any:
        """
        åˆ›å»ºAnthropic Claude LLMå®ä¾‹
        
        Args:
            config: Anthropicé…ç½®
            
        Returns:
            Anthropic Claude LLMå®ä¾‹
        """
        api_key = config.get("api_key") or os.getenv("ANTHROPIC_API_KEY")
        if not api_key:
            raise ValueError("æœªæ‰¾åˆ°Anthropic APIå¯†é’¥ï¼Œè¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ANTHROPIC_API_KEY")
        
        return ChatAnthropic(
            anthropic_api_key=api_key,
            model=config.get("model", "claude-3-sonnet-20240229"),
            temperature=config.get("temperature", 0.7),
            max_tokens=config.get("max_tokens", 1000)
        )
    
    @staticmethod
    def _create_huggingface_llm(config: Dict[str, Any]) -> Any:
        """
        åˆ›å»ºHugging Face LLMå®ä¾‹
        
        Args:
            config: Hugging Faceé…ç½®
            
        Returns:
            Hugging Face LLMå®ä¾‹
        """
        api_key = config.get("api_key") or os.getenv("HUGGINGFACEHUB_API_TOKEN")
        if not api_key:
            raise ValueError("æœªæ‰¾åˆ°Hugging Face APIå¯†é’¥ï¼Œè¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®æˆ–è®¾ç½®ç¯å¢ƒå˜é‡HUGGINGFACEHUB_API_TOKEN")
        
        os.environ["HUGGINGFACEHUB_API_TOKEN"] = api_key
        
        return HuggingFaceHub(
            repo_id=config.get("model", "microsoft/DialoGPT-medium"),
            model_kwargs={"temperature": config.get("temperature", 0.7)},
            huggingfacehub_api_token=api_key
        )
    
    @staticmethod
    def _create_siliconflow_llm(config: Dict[str, Any]) -> Any:
        """
        åˆ›å»ºç¡…åŸºæµåŠ¨LLMå®ä¾‹
        
        Args:
            config: ç¡…åŸºæµåŠ¨é…ç½®
            
        Returns:
            ç¡…åŸºæµåŠ¨LLMå®ä¾‹
        """
        # ğŸ†• ä¼˜å…ˆä½¿ç”¨ EnvManager
        from src.config.env_manager import EnvManager
        api_key = config.get("api_key") or EnvManager.SILICONFLOW_API_KEY
        if not api_key:
            raise ValueError("æœªæ‰¾åˆ°ç¡…åŸºæµåŠ¨APIå¯†é’¥ï¼Œè¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®æˆ–è®¾ç½®ç¯å¢ƒå˜é‡SILICONFLOW_API_KEY")
        
        model = config.get("model", "Pro/deepseek-ai/DeepSeek-V3.1-Terminus")
        base_url = config.get("base_url", "https://api.siliconflow.cn/v1")
        
        # ä½¿ç”¨ChatOpenAIæ¥è¿æ¥ç¡…åŸºæµåŠ¨APIï¼Œå› ä¸ºå®ƒå…¼å®¹OpenAI APIæ ¼å¼
        # ä½¿ç”¨å®é™…çš„æ¨¡å‹åç§°ï¼Œè€Œä¸æ˜¯gpt-3.5-turbo
        llm = ChatOpenAI(
            openai_api_key=api_key,
            model_name=model,  # ä½¿ç”¨å®é™…çš„æ¨¡å‹åç§°
            temperature=config.get("temperature", 0.7),
            max_tokens=config.get("max_tokens", 1000),
            top_p=config.get("top_p", 1.0),
            frequency_penalty=config.get("frequency_penalty", 0.0),
            presence_penalty=config.get("presence_penalty", 0.0),
            openai_api_base=base_url
        )
        
        # å­˜å‚¨å®é™…çš„æ¨¡å‹åç§°ï¼Œä»¥ä¾¿åç»­ä½¿ç”¨
        # ä½¿ç”¨__dict__æ·»åŠ å±æ€§ï¼Œé¿å…PydanticéªŒè¯é”™è¯¯
        llm.__dict__['actual_model'] = model
        
        return llm