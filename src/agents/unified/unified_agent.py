"""
ç»Ÿä¸€æ™ºèƒ½ä½“æ¨¡å—
ç»“åˆReActæ¶æ„ã€å¤šè½®å¯¹è¯è®°å¿†ã€å·¥å…·è°ƒç”¨å’Œå¯é…ç½®è¾“å‡ºæ ¼å¼
"""

import warnings
from typing import Dict, Any, List, Optional
from enum import Enum  # ğŸ†• å¯¼å…¥æšä¸¾
from langchain.agents import AgentExecutor, create_react_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import BaseMessage
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.chat_history import InMemoryChatMessageHistory
from src.infrastructure.llm.llm_factory import LLMFactory
from src.agents.shared.tools import get_tools, get_tools_for_agent
from src.agents.shared.output_formatter import OutputFormatter, OutputFormat
from src.agents.shared.streaming_handler import StreamingDisplayHandler, SimpleStreamingHandler
from src.config.config_loader import config_loader
from src.prompts.prompt_loader import prompt_loader
from src.core.services.context_manager import ConversationBufferWithSummary, ContextManager
from src.core.services.context_tracker import ContextTracker  # ğŸ†• å¯¼å…¥ä¸Šä¸‹æ–‡è¿½è¸ªå™¨


# ğŸ†• æ™ºèƒ½ä½“åœæ­¢åŸå› æšä¸¾
class AgentStopReason(Enum):
    """æ™ºèƒ½ä½“åœæ­¢åŸå› """
    COMPLETED = "completed"  # ä»»åŠ¡å®Œæˆ
    ITERATION_LIMIT = "iteration_limit"  # è¾¾åˆ°è¿­ä»£é™åˆ¶
    TIME_LIMIT = "time_limit"  # è¾¾åˆ°æ—¶é—´é™åˆ¶
    ERROR = "error"  # å‘ç”Ÿé”™è¯¯
    USER_INTERRUPT = "user_interrupt"  # ç”¨æˆ·ä¸­æ–­


class UnifiedAgent:
    """ç»Ÿä¸€æ™ºèƒ½ä½“ï¼Œç»“åˆReActæ¶æ„ã€å¤šè½®å¯¹è¯è®°å¿†ã€å·¥å…·è°ƒç”¨å’Œå¯é…ç½®è¾“å‡ºæ ¼å¼"""
    
    def __init__(
        self, 
        provider: Optional[str] = None, 
        memory: bool = True,
        redis_url: Optional[str] = None,
        session_id: Optional[str] = None,
        model_name: Optional[str] = None,
        streaming_style: str = "simple",  # simple, detailed, none
        **kwargs
    ):
        """
        åˆå§‹åŒ–ç»Ÿä¸€æ™ºèƒ½ä½“
        
        Args:
            provider: LLMæä¾›å•†
            memory: æ˜¯å¦å¯ç”¨è®°å¿†åŠŸèƒ½
            redis_url: Redisè¿æ¥URLï¼Œå¦‚æœä¸ºNoneåˆ™ä»é…ç½®æ–‡ä»¶è·å–
            session_id: ä¼šè¯IDï¼Œç”¨äºåŒºåˆ†ä¸åŒå¯¹è¯
            model_name: æ¨¡å‹åç§°
            streaming_style: æµå¼è¾“å‡ºæ ·å¼ (simple=ç®€æ´, detailed=è¯¦ç»†, none=æ— )
            **kwargs: é¢å¤–çš„LLMå‚æ•°
        """
        self.streaming_style = streaming_style
        # å¤„ç†æ¨¡å‹åç§°å‚æ•°
        if model_name:
            kwargs["model_name"] = model_name
            
        self.llm = LLMFactory.create_llm(provider, **kwargs)
        self.agent_config = config_loader.get_agent_config()
        self.output_config = config_loader.get_output_config()
        
        # å¦‚æœæ²¡æœ‰æä¾›redis_urlï¼Œä»é…ç½®æ–‡ä»¶è·å–
        if redis_url is None and memory:
            redis_config = config_loader.get_redis_config()
            if redis_config:
                host = redis_config.get("host", "localhost")
                port = redis_config.get("port", 6379)
                db = redis_config.get("db", 0)
                password = redis_config.get("password", "")
                
                # æ„å»ºRedis URL
                if password:
                    redis_url = f"redis://:{password}@{host}:{port}/{db}"
                else:
                    redis_url = f"redis://{host}:{port}/{db}"
        
        self.memory = self._create_memory(memory, redis_url, session_id)
        
        # ğŸ†• åˆå§‹åŒ–ä¸Šä¸‹æ–‡è¿½è¸ªå™¨
        self.context_tracker = ContextTracker(max_history=10)
        
        # ä½¿ç”¨æ–°çš„åŠ¨æ€å·¥å…·åŠ è½½å™¨
        try:
            # å°è¯•ä½¿ç”¨æ™ºèƒ½ä½“ç‰¹å®šçš„å·¥å…·é…ç½®
            self.tools = get_tools_for_agent("unified_agent")
        except Exception as e:
            print(f"ä½¿ç”¨æ™ºèƒ½ä½“ç‰¹å®šå·¥å…·é…ç½®å¤±è´¥: {e}")
            # å›é€€åˆ°é»˜è®¤å·¥å…·åˆ—è¡¨
            self.tools = get_tools(["calculator", "search", "time", "crewai_generator", "crewai_runtime"]) if self.agent_config.get("enable_tools", True) else []
        
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è¾“å‡ºæ ¼å¼åˆå§‹åŒ–OutputFormatter
        output_format = self.output_config.get("format", "normal")
        self.output_formatter = OutputFormatter(output_format, self.output_config)
        
        self.agent = self._create_agent()
        self.agent_executor = self._create_agent_executor()
        
        # å­˜å‚¨ä¼šè¯ä¿¡æ¯
        self.session_id = session_id or "default"
        self.redis_url = redis_url
    
    def _create_memory(self, memory_enabled: bool, redis_url: Optional[str], session_id: Optional[str]):
        """
        åˆ›å»ºè®°å¿†ç»„ä»¶
        
        Args:
            memory_enabled: æ˜¯å¦å¯ç”¨è®°å¿†
            redis_url: Redisè¿æ¥URL
            session_id: ä¼šè¯ID
            
        Returns:
            è®°å¿†ç»„ä»¶å®ä¾‹
        """
        if not memory_enabled:
            return None
        
        # å¦‚æœæä¾›äº†Redis URLï¼Œä½¿ç”¨Rediså­˜å‚¨
        if redis_url:
            try:
                from src.storage.redis_chat_history import RedisChatMessageHistory
                print(f"âœ… ä½¿ç”¨Rediså­˜å‚¨å¯¹è¯å†å² (ä¼šè¯ID: {session_id or 'default'})")
                return RedisChatMessageHistory(
                    session_id=session_id or "default",
                    redis_url=redis_url
                )
            except ImportError:
                print("âš ï¸  Rediså­˜å‚¨ä¸å¯ç”¨ï¼Œå›é€€åˆ°å†…å­˜å­˜å‚¨ï¼ˆå¸¦æ‘˜è¦åŠŸèƒ½ï¼‰")
            except Exception as e:
                print(f"âš ï¸  Redisè¿æ¥å¤±è´¥: {e}ï¼Œå›é€€åˆ°å†…å­˜å­˜å‚¨ï¼ˆå¸¦æ‘˜è¦åŠŸèƒ½ï¼‰")
        
        # ä½¿ç”¨å†…å­˜å­˜å‚¨ï¼ˆå¸¦æ‘˜è¦å’Œå‹ç¼©åŠŸèƒ½ï¼‰
        unified_config = config_loader.get_specific_agent_config("unified_agent")
        memory_config = unified_config.get("memory", {})
        
        max_tokens = memory_config.get("max_conversation_length", 4000)
        summary_threshold = memory_config.get("summary_interval", 10)
        
        print(f"âœ… ä½¿ç”¨å†…å­˜å­˜å‚¨å¯¹è¯å†å²ï¼ˆå¸¦è‡ªåŠ¨æ‘˜è¦åŠŸèƒ½ï¼Œæ¯{summary_threshold}è½®å¯¹è¯è‡ªåŠ¨å‹ç¼©ï¼‰")
        
        # ä½¿ç”¨å¸¦æ‘˜è¦åŠŸèƒ½çš„å¯¹è¯ç¼“å†²åŒº
        return ConversationBufferWithSummary(
            llm=self.llm,
            max_tokens=max_tokens,
            summary_threshold=summary_threshold,
            keep_recent=4  # ä¿ç•™æœ€è¿‘4è½®å®Œæ•´å¯¹è¯
        )
    
    def _create_agent(self):
        """
        åˆ›å»ºæ™ºèƒ½ä½“
        
        Returns:
            æ™ºèƒ½ä½“å®ä¾‹
        """
        # ä½¿ç”¨ReActæ¶æ„ä½œä¸ºåŸºç¡€ï¼Œä½†ç»“åˆäº†å…¶ä»–æ™ºèƒ½ä½“çš„ç‰¹æ€§
        # è·å–ç»Ÿä¸€æ™ºèƒ½ä½“çš„é…ç½®
        unified_config = config_loader.get_specific_agent_config("unified_agent")
        
        # ä»é…ç½®ä¸­è·å–æç¤ºè¯é”®
        system_prompt_key = unified_config.get("system_prompt", "supply_chain_planning")
        
        try:
            # å°è¯•ä»é…ç½®æ–‡ä»¶åŠ è½½æç¤ºè¯
            prompts_config = config_loader.get_prompts_config()
            prompts = prompts_config.get("prompts", {})
            
            # è·å–ç³»ç»Ÿæç¤ºè¯
            prompt_config = prompts.get(system_prompt_key, {})
            system_prompt_template = prompt_config.get("template", "")
            
            if not system_prompt_template:
                # å›é€€åˆ°ç¡¬ç¼–ç çš„æç¤ºè¯
                print(f"æœªæ‰¾åˆ°é…ç½®çš„æç¤ºè¯ {system_prompt_key}ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯")
                system_prompt_template = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ä¾›åº”é“¾ç®¡ç†ä¸“å®¶å’Œä¸šåŠ¡æµç¨‹è§„åˆ’é¡¾é—®ã€‚
ä½ çš„ä¸»è¦èŒè´£æ˜¯ç†è§£ç”¨æˆ·çš„ä¾›åº”é“¾éœ€æ±‚ï¼Œæä¾›ä¸“ä¸šçš„ä¸šåŠ¡æµç¨‹è§„åˆ’å»ºè®®ã€‚

å½“ç”¨æˆ·è¯¢é—®å…³äºn8nå·¥ä½œæµæˆ–æ™ºèƒ½ä½“å¯¹è¯ç”Ÿæˆæ—¶ï¼Œä½ åº”è¯¥ï¼š
1. æ˜ç¡®å‘Šè¯‰ç”¨æˆ·ä½ å¯ä»¥ä½¿ç”¨n8n_mcp_generatorå·¥å…·æ¥ç”Ÿæˆå·¥ä½œæµ
2. è¯¢é—®ç”¨æˆ·éœ€è¦ä»€ä¹ˆç±»å‹çš„å·¥ä½œæµæˆ–å¯¹è¯
3. ä½¿ç”¨n8n_mcp_generatorå·¥å…·æ¥å®Œæˆä»»åŠ¡

{agent_scratchpad}"""
            
            # è·å–å½“å‰æ—¶é—´ä¿¡æ¯
            from datetime import datetime
            current_datetime = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            current_date = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
            current_year = datetime.now().year
            
            # æ„å»ºå®Œæ•´çš„Reactæç¤ºè¯æ¨¡æ¿ - ä½¿ç”¨æ ‡å‡†è‹±æ–‡æ ¼å¼é¿å…è§£æé—®é¢˜ï¼ŒåŒ…å«å¯¹è¯å†å²å’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥
            template = f"""Current Date and Time: {current_datetime} (Beijing Time, UTC+8)
Current Year: {current_year}
Today is: {current_date}

IMPORTANT: When analyzing trends, news, market conditions, or any time-sensitive information, 
always consider the current date above. Use the 'time' tool if you need to verify the current time.

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ§  CONTEXT-AWARE RULES                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âš ï¸ CRITICAL: Always check conversation history and understand context before selecting tools!

ğŸ“Œ Tool Selection Guidelines:

1. **When user says "è¿è¡Œå®ƒ"/"æ‰§è¡Œå®ƒ"/"å¯åŠ¨å®ƒ"/"run it":**
   - CHECK the previous action first!
   - If previous action was "crewai_generator" â†’ Use "crewai_runtime"
   - If previous action was "n8n_generate_and_create_workflow" â†’ Explain workflow was created
   - NEVER randomly choose a tool when context exists

2. **For CrewAI-related tasks:**
   - User wants to CREATE/DESIGN team config â†’ Use "crewai_generator"
   - User wants to RUN/EXECUTE team â†’ Use "crewai_runtime"
   - Keywords: "å›¢é˜Ÿ", "agent team", "crew", "åä½œ"

3. **For n8n workflow tasks:**
   - ONLY use "n8n_generate_and_create_workflow" when explicitly asked for workflows
   - Keywords: "å·¥ä½œæµ", "workflow", "n8n", "è‡ªåŠ¨åŒ–", "automation"
   - NOT for data analysis or research tasks

4. **Context dependency indicators:**
   - Pronouns: "å®ƒ", "è¿™ä¸ª", "é‚£ä¸ª", "ä»–", "å¥¹"
   - Time references: "åˆšæ‰", "ä¸Šä¸€æ­¥", "ä¹‹å‰", "åˆšåˆš"
   - Action verbs: "è¿è¡Œ", "æ‰§è¡Œ", "å¯åŠ¨", "ç»§ç»­"
   
   â†’ When these appear, ALWAYS review conversation history!

Answer the following questions as best you can. You have access to the following tools:

{{tools}}

Use the following format:

Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [{{tool_names}}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Begin!

Previous conversation history:
{{chat_history}}

New question: {{input}}
Thought:{{agent_scratchpad}}"""
            
            prompt = ChatPromptTemplate.from_messages([
                ("system", template)
            ])
            
        except Exception as e:
            print(f"åŠ è½½æç¤ºè¯é…ç½®å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯")
            # ä½¿ç”¨é»˜è®¤çš„Reactæç¤ºè¯
            from langchain import hub
            try:
                prompt = hub.pull("hwchase17/react-chat")
            except Exception as hub_error:
                print(f"æ— æ³•ä»LangChain Hubè·å–æç¤ºè¯: {hub_error}")
                # æœ€åçš„å›é€€æ–¹æ¡ˆ
                template = """ä½ æ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„é€šç”¨æ™ºèƒ½åŠ©æ‰‹ã€‚

ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·:
{tools}

å·¥å…·åç§°:
{tool_names}

Question: {input}
Thought:{agent_scratchpad}"""
                prompt = ChatPromptTemplate.from_template(template)
        
        return create_react_agent(self.llm, self.tools, prompt)
    
    def _create_agent_executor(self):
        """
        åˆ›å»ºæ™ºèƒ½ä½“æ‰§è¡Œå™¨
        
        Returns:
            æ™ºèƒ½ä½“æ‰§è¡Œå™¨å®ä¾‹
        """
        # ä»é…ç½®æ–‡ä»¶è¯»å–è¿­ä»£é™åˆ¶å‚æ•°
        unified_config = config_loader.get_specific_agent_config("unified_agent")
        parameters = unified_config.get("parameters", {})
        max_iterations = parameters.get("max_iterations", 25)  # é»˜è®¤25æ¬¡
        max_execution_time = parameters.get("max_execution_time", 180)  # é»˜è®¤3åˆ†é’Ÿ
        
        # åˆ›å»ºæµå¼å¤„ç†å™¨ï¼ˆæ ¹æ®é…ç½®é€‰æ‹©ï¼‰
        callbacks = []
        verbose_mode = False
        
        if self.streaming_style == "detailed":
            # è¯¦ç»†æ¨¡å¼ï¼šæ˜¾ç¤ºå®Œæ•´çš„æ€è€ƒè¿‡ç¨‹
            streaming_handler = StreamingDisplayHandler(verbose=True, show_colors=True)
            callbacks = [streaming_handler]
        elif self.streaming_style == "simple":
            # ç®€æ´æ¨¡å¼ï¼šæ˜¾ç¤ºç®€åŒ–çš„æ‰§è¡Œè¿‡ç¨‹
            streaming_handler = SimpleStreamingHandler()
            callbacks = [streaming_handler]
        elif self.streaming_style == "none":
            # æ— æµå¼è¾“å‡ºï¼šåªæ˜¾ç¤ºæœ€ç»ˆç»“æœ
            verbose_mode = False
        else:
            # é»˜è®¤ä½¿ç”¨ç®€æ´æ¨¡å¼
            streaming_handler = SimpleStreamingHandler()
            callbacks = [streaming_handler]
        
        # åˆ›å»ºåŸºç¡€çš„AgentExecutor
        executor = AgentExecutor(
            agent=self.agent,
            tools=self.tools,
            verbose=verbose_mode,  # æ ¹æ®æ¨¡å¼å†³å®šæ˜¯å¦verbose
            handle_parsing_errors=True,
            max_iterations=max_iterations,  # ä»é…ç½®æ–‡ä»¶è¯»å–è¿­ä»£æ¬¡æ•°
            max_execution_time=max_execution_time,  # ä»é…ç½®æ–‡ä»¶è¯»å–æ‰§è¡Œæ—¶é—´
            callbacks=callbacks if callbacks else None,  # æ·»åŠ æµå¼å¤„ç†å™¨
            agent_kwargs={
                "tool_names": [tool.name for tool in self.tools]
            }
        )
        
        if self.memory:
            # ä½¿ç”¨RunnableWithMessageHistoryåŒ…è£…AgentExecutorï¼Œå®ç°è®°å¿†åŠŸèƒ½
            def get_session_history(session_id: str):
                """è·å–ä¼šè¯å†å²ï¼Œç¡®ä¿è¿”å›æ­£ç¡®çš„ memory å¯¹è±¡"""
                # å¯¹äº ConversationBufferWithSummaryï¼Œå®ƒå®ç°äº† BaseChatMessageHistory æ¥å£
                # å¯¹äº RedisChatMessageHistoryï¼Œä¹Ÿå®ç°äº†åŒæ ·çš„æ¥å£
                return self.memory
            
            agent_with_history = RunnableWithMessageHistory(
                executor,
                get_session_history,
                input_messages_key="input",
                history_messages_key="chat_history",
            )
            return agent_with_history
        else:
            # å¦‚æœä¸éœ€è¦è®°å¿†åŠŸèƒ½ï¼Œç›´æ¥ä½¿ç”¨AgentExecutor
            return executor
    
    def run(self, query: str, session_id: str = "default") -> Dict[str, Any]:
        """
        è¿è¡Œæ™ºèƒ½ä½“
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            session_id: ä¼šè¯IDï¼Œç”¨äºåŒºåˆ†ä¸åŒå¯¹è¯
            
        Returns:
            åŒ…å«å“åº”å’Œå…ƒæ•°æ®çš„å­—å…¸
        """
        try:
            # ğŸ†• 1. è®°å½•æŸ¥è¯¢åˆ°ä¸Šä¸‹æ–‡è¿½è¸ªå™¨
            self.context_tracker.add_query(query)
            
            # ğŸ†• 2. æ£€æŸ¥æ˜¯å¦ä¾èµ–ä¸Šä¸‹æ–‡ï¼Œç”Ÿæˆå¢å¼ºæç¤º
            enhanced_query = query
            if self.context_tracker.is_context_dependent(query):
                enhanced_query = self.context_tracker.generate_context_hint(query)
                if self.streaming_style != "none":
                    print(f"ğŸ” æ£€æµ‹åˆ°ä¸Šä¸‹æ–‡ä¾èµ–æŸ¥è¯¢ï¼Œå¢å¼ºæç¤ºå·²ç”Ÿæˆ")
            
            # æ‰§è¡Œæ™ºèƒ½ä½“
            if self.memory:
                # ä½¿ç”¨RunnableWithMessageHistoryçš„invokeæ–¹æ³•
                # ä¸éœ€è¦åœ¨è¿™é‡Œæ·»åŠ intermediate_stepsï¼Œå› ä¸ºAgentExecutorä¼šå¤„ç†
                response = self.agent_executor.invoke(
                    {"input": enhanced_query},  # ğŸ†• ä½¿ç”¨å¢å¼ºåçš„æŸ¥è¯¢
                    config={"configurable": {"session_id": session_id}}
                )
            else:
                # ä½¿ç”¨AgentExecutorçš„invokeæ–¹æ³•
                response = self.agent_executor.invoke({"input": enhanced_query})  # ğŸ†• ä½¿ç”¨å¢å¼ºåçš„æŸ¥è¯¢
            
            # å¤„ç†ä¸åŒç±»å‹çš„å“åº”
            if hasattr(response, 'get'):
                # å­—å…¸ç±»å‹å“åº”
                raw_output = response.get("output", "æœªæ”¶åˆ°æœ‰æ•ˆå“åº”")
                # ğŸ†• æå–ä¸­é—´æ­¥éª¤ï¼ˆå·¥å…·è°ƒç”¨ï¼‰
                intermediate_steps = response.get("intermediate_steps", [])
            elif hasattr(response, 'return_values'):
                # AgentFinishå¯¹è±¡ç±»å‹å“åº”
                raw_output = response.return_values.get("output", "æœªæ”¶åˆ°æœ‰æ•ˆå“åº”")
                intermediate_steps = []
            else:
                # å…¶ä»–ç±»å‹ï¼Œå°è¯•ç›´æ¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                raw_output = str(response)
                intermediate_steps = []
            
            # ğŸ†• 3. è®°å½•å·¥å…·è°ƒç”¨åˆ°ä¸Šä¸‹æ–‡è¿½è¸ªå™¨
            for step in intermediate_steps:
                if len(step) >= 2:
                    action, observation = step[0], step[1]
                    if hasattr(action, 'tool'):
                        self.context_tracker.add_tool_call(action.tool, observation)
            
            # æ„å»ºå…ƒæ•°æ®
            metadata = {
                "query": query,
                "tools_used": [tool.name for tool in self.tools],
                "agent_type": "unified",
                "output_format": self.output_formatter.get_format(),
                "session_id": session_id,
                "has_memory": self.memory is not None,
                "memory_type": "redis" if self.redis_url else "in_memory",
                # ğŸ†• æ·»åŠ ä¸Šä¸‹æ–‡è¿½è¸ªå™¨ç»Ÿè®¡ä¿¡æ¯
                "context_stats": self.context_tracker.get_statistics()
            }
            
            # ä½¿ç”¨OutputFormatteræ ¼å¼åŒ–å“åº”
            formatted_response = self.output_formatter.format_response(raw_output, metadata)
            
            return {
                "response": formatted_response,
                "metadata": metadata
            }
        except Exception as e:
            error_msg = f"æ™ºèƒ½ä½“è¿è¡Œå‡ºé”™: {str(e)}"
            metadata = {
                "query": query,
                "error": str(e),
                "agent_type": "unified",
                "output_format": self.output_formatter.get_format(),
                "session_id": session_id
            }
            return {
                "response": error_msg,
                "metadata": metadata
            }
    
    async def arun(self, query: str, session_id: str = "default") -> Dict[str, Any]:
        """
        å¼‚æ­¥è¿è¡Œæ™ºèƒ½ä½“
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            session_id: ä¼šè¯IDï¼Œç”¨äºåŒºåˆ†ä¸åŒå¯¹è¯
            
        Returns:
            åŒ…å«å“åº”å’Œå…ƒæ•°æ®çš„å­—å…¸
        """
        try:
            if self.memory:
                # ä½¿ç”¨RunnableWithMessageHistoryçš„ainvokeæ–¹æ³•
                # ä¸éœ€è¦åœ¨è¿™é‡Œæ·»åŠ intermediate_stepsï¼Œå› ä¸ºAgentExecutorä¼šå¤„ç†
                response = await self.agent_executor.ainvoke(
                    {"input": query},
                    config={"configurable": {"session_id": session_id}}
                )
            else:
                # ä½¿ç”¨AgentExecutorçš„ainvokeæ–¹æ³•
                response = await self.agent_executor.ainvoke({"input": query})
            
            # å¤„ç†ä¸åŒç±»å‹çš„å“åº”
            if hasattr(response, 'get'):
                # å­—å…¸ç±»å‹å“åº”
                raw_output = response.get("output", "æœªæ”¶åˆ°æœ‰æ•ˆå“åº”")
            elif hasattr(response, 'return_values'):
                # AgentFinishå¯¹è±¡ç±»å‹å“åº”
                raw_output = response.return_values.get("output", "æœªæ”¶åˆ°æœ‰æ•ˆå“åº”")
            else:
                # å…¶ä»–ç±»å‹ï¼Œå°è¯•ç›´æ¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                raw_output = str(response)
            
            # æ„å»ºå…ƒæ•°æ®
            metadata = {
                "query": query,
                "tools_used": [tool.name for tool in self.tools],
                "agent_type": "unified",
                "output_format": self.output_formatter.get_format(),
                "session_id": session_id,
                "has_memory": self.memory is not None,
                "memory_type": "redis" if self.redis_url else "in_memory"
            }
            
            # ä½¿ç”¨OutputFormatteræ ¼å¼åŒ–å“åº”
            formatted_response = self.output_formatter.format_response(raw_output, metadata)
            
            return {
                "response": formatted_response,
                "metadata": metadata
            }
        except Exception as e:
            error_msg = f"æ™ºèƒ½ä½“å¼‚æ­¥è¿è¡Œå‡ºé”™: {str(e)}"
            metadata = {
                "query": query,
                "error": str(e),
                "agent_type": "unified",
                "output_format": self.output_formatter.get_format(),
                "session_id": session_id
            }
            return {
                "response": error_msg,
                "metadata": metadata
            }
    
    def chat(self, message: str, history: Optional[List[BaseMessage]] = None, session_id: str = "default") -> Dict[str, Any]:
        """
        å¯¹è¯æ¨¡å¼
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            history: å¯¹è¯å†å²
            session_id: ä¼šè¯IDï¼Œç”¨äºåŒºåˆ†ä¸åŒå¯¹è¯
            
        Returns:
            åŒ…å«å“åº”å’Œå…ƒæ•°æ®çš„å­—å…¸
        """
        try:
            if history and self.memory:
                # å¦‚æœæä¾›äº†å†å²è®°å½•ï¼Œæ›´æ–°è®°å¿†
                self.memory.messages = history
            
            if self.memory:
                # ä½¿ç”¨RunnableWithMessageHistoryçš„invokeæ–¹æ³•
                # ä¸éœ€è¦åœ¨è¿™é‡Œæ·»åŠ intermediate_stepsï¼Œå› ä¸ºAgentExecutorä¼šå¤„ç†
                response = self.agent_executor.invoke(
                    {"input": message},
                    config={"configurable": {"session_id": session_id}}
                )
            else:
                # ä½¿ç”¨AgentExecutorçš„invokeæ–¹æ³•
                response = self.agent_executor.invoke({"input": message})
            
            # å¤„ç†ä¸åŒç±»å‹çš„å“åº”
            if hasattr(response, 'get'):
                # å­—å…¸ç±»å‹å“åº”
                raw_output = response.get("output", "æœªæ”¶åˆ°æœ‰æ•ˆå“åº”")
            elif hasattr(response, 'return_values'):
                # AgentFinishå¯¹è±¡ç±»å‹å“åº”
                raw_output = response.return_values.get("output", "æœªæ”¶åˆ°æœ‰æ•ˆå“åº”")
            else:
                # å…¶ä»–ç±»å‹ï¼Œå°è¯•ç›´æ¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                raw_output = str(response)
            
            # æ„å»ºå…ƒæ•°æ®
            metadata = {
                "query": message,
                "has_history": history is not None,
                "agent_type": "unified",
                "output_format": self.output_formatter.get_format(),
                "session_id": session_id,
                "has_memory": self.memory is not None,
                "memory_type": "redis" if self.redis_url else "in_memory"
            }
            
            # ä½¿ç”¨OutputFormatteræ ¼å¼åŒ–å“åº”
            formatted_response = self.output_formatter.format_response(raw_output, metadata)
            
            return {
                "response": formatted_response,
                "metadata": metadata
            }
        except Exception as e:
            error_msg = f"å¯¹è¯å‡ºé”™: {str(e)}"
            metadata = {
                "query": message,
                "error": str(e),
                "agent_type": "unified",
                "output_format": self.output_formatter.get_format(),
                "session_id": session_id
            }
            return {
                "response": error_msg,
                "metadata": metadata
            }
    
    def stream(self, query: str, session_id: str = "default"):
        """
        æµå¼è¿è¡Œæ™ºèƒ½ä½“
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            session_id: ä¼šè¯IDï¼Œç”¨äºåŒºåˆ†ä¸åŒå¯¹è¯
            
        Yields:
            æµå¼è¾“å‡ºçš„å“åº”ç‰‡æ®µ
        """
        try:
            if self.memory:
                # ä½¿ç”¨RunnableWithMessageHistoryçš„streamæ–¹æ³•
                # ä¸éœ€è¦åœ¨è¿™é‡Œæ·»åŠ intermediate_stepsï¼Œå› ä¸ºAgentExecutorä¼šå¤„ç†
                for chunk in self.agent_executor.stream(
                    {"input": query},
                    config={"configurable": {"session_id": session_id}}
                ):
                    yield from self._process_stream_chunk(chunk, query)
            else:
                # ä½¿ç”¨AgentExecutorçš„streamæ–¹æ³•è¿›è¡Œæµå¼è¾“å‡º
                for chunk in self.agent_executor.stream({"input": query}):
                    yield from self._process_stream_chunk(chunk, query)
                    
        except Exception as e:
            error_msg = f"æ™ºèƒ½ä½“æµå¼è¿è¡Œå‡ºé”™: {str(e)}"
            metadata = {
                "query": query,
                "error": str(e),
                "agent_type": "unified",
                "output_format": self.output_formatter.get_format(),
                "session_id": session_id
            }
            formatted_error = self.output_formatter.format_response(error_msg, metadata)
            yield {
                "response": formatted_error,
                "metadata": metadata
            }
    
    async def astream(self, query: str, session_id: str = "default"):
        """
        å¼‚æ­¥æµå¼è¿è¡Œæ™ºèƒ½ä½“
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            session_id: ä¼šè¯IDï¼Œç”¨äºåŒºåˆ†ä¸åŒå¯¹è¯
            
        Yields:
            å¼‚æ­¥æµå¼è¾“å‡ºçš„å“åº”ç‰‡æ®µ
        """
        try:
            if self.memory:
                # ä½¿ç”¨RunnableWithMessageHistoryçš„astreamæ–¹æ³•
                # ä¸éœ€è¦åœ¨è¿™é‡Œæ·»åŠ intermediate_stepsï¼Œå› ä¸ºAgentExecutorä¼šå¤„ç†
                async for chunk in self.agent_executor.astream(
                    {"input": query},
                    config={"configurable": {"session_id": session_id}}
                ):
                    for processed_chunk in self._process_stream_chunk(chunk, query):
                        yield processed_chunk
            else:
                # ä½¿ç”¨AgentExecutorçš„astreamæ–¹æ³•è¿›è¡Œå¼‚æ­¥æµå¼è¾“å‡º
                async for chunk in self.agent_executor.astream({"input": query}):
                    for processed_chunk in self._process_stream_chunk(chunk, query):
                        yield processed_chunk
                    
        except Exception as e:
            error_msg = f"æ™ºèƒ½ä½“å¼‚æ­¥æµå¼è¿è¡Œå‡ºé”™: {str(e)}"
            metadata = {
                "query": query,
                "error": str(e),
                "agent_type": "unified",
                "output_format": self.output_formatter.get_format(),
                "session_id": session_id
            }
            formatted_error = self.output_formatter.format_response(error_msg, metadata)
            yield {
                "response": formatted_error,
                "metadata": metadata
            }
    
    def _process_stream_chunk(self, chunk: Dict[str, Any], query: str):
        """
        å¤„ç†æµå¼è¾“å‡ºå—
        
        Args:
            chunk: æµå¼è¾“å‡ºå—
            query: åŸå§‹æŸ¥è¯¢
            
        Yields:
            å¤„ç†åçš„è¾“å‡ºç‰‡æ®µ
        """
        # å¤„ç†ä¸åŒç±»å‹çš„è¾“å‡ºå—
        if isinstance(chunk, dict) and "output" in chunk:
            # å­—å…¸ç±»å‹ä¸”æœ‰outputé”®
            raw_output = chunk["output"]
            metadata = {
                "query": query,
                "tools_used": [tool.name for tool in self.tools],
                "agent_type": "unified",
                "output_format": self.output_formatter.get_format(),
                "session_id": self.session_id,
                "has_memory": self.memory is not None,
                "memory_type": "redis" if self.redis_url else "in_memory"
            }
            yield {
                "response": raw_output,
                "metadata": metadata
            }
        elif hasattr(chunk, 'return_values') and 'output' in chunk.return_values:
            # AgentFinishå¯¹è±¡ç±»å‹
            raw_output = chunk.return_values['output']
            metadata = {
                "query": query,
                "tools_used": [tool.name for tool in self.tools],
                "agent_type": "unified",
                "output_format": self.output_formatter.get_format(),
                "session_id": self.session_id,
                "has_memory": self.memory is not None,
                "memory_type": "redis" if self.redis_url else "in_memory"
            }
            yield {
                "response": raw_output,
                "metadata": metadata
            }
        elif isinstance(chunk, dict) and "steps" in chunk:
            # ä¸­é—´æ­¥éª¤ - ä¿®å¤intermediate_stepsè®¿é—®é—®é¢˜
            for step in chunk["steps"]:
                # æ›´å®‰å…¨çš„æ–¹å¼è®¿é—®æ­¥éª¤å†…å®¹
                if isinstance(step, (tuple, list)) and len(step) >= 2:
                    # æ–°ç‰ˆæœ¬å¯èƒ½æ˜¯(action, observation)å…ƒç»„æ ¼å¼
                    action, observation = step[0], step[1]
                    
                    # å¤„ç†action
                    if hasattr(action, "tool"):
                        tool_name = action.tool
                        tool_input = getattr(action, "tool_input", str(action))
                        action_info = f"\nğŸ”§ ä½¿ç”¨å·¥å…·: {tool_name}\nğŸ“ è¾“å…¥: {tool_input}\n"
                        yield {
                            "response": action_info,
                            "metadata": {
                                "query": query,
                                "agent_type": "unified",
                                "session_id": self.session_id,
                                "is_intermediate_step": True
                            }
                        }
                    else:
                        action_info = f"\nğŸ”§ æ‰§è¡Œæ“ä½œ: {str(action)}\n"
                        yield {
                            "response": action_info,
                            "metadata": {
                                "query": query,
                                "agent_type": "unified",
                                "session_id": self.session_id,
                                "is_intermediate_step": True
                            }
                        }
                    
                    # å¤„ç†observation
                    obs_info = f"ğŸ“Š ç»“æœ: {str(observation)}\n"
                    yield {
                        "response": obs_info,
                        "metadata": {
                            "query": query,
                            "agent_type": "unified",
                            "session_id": self.session_id,
                            "is_intermediate_step": True
                        }
                    }
                elif hasattr(step, "action") and hasattr(step, "observation"):
                    # æ—§ç‰ˆæœ¬å¯¹è±¡æ ¼å¼
                    action = step.action
                    observation = step.observation
                    
                    # è¾“å‡ºåŠ¨ä½œä¿¡æ¯
                    action_info = f"\nğŸ”§ ä½¿ç”¨å·¥å…·: {action.tool}\n"
                    action_info += f"ğŸ“ è¾“å…¥: {action.tool_input}\n"
                    yield {
                        "response": action_info,
                        "metadata": {
                            "query": query,
                            "agent_type": "unified",
                            "session_id": self.session_id,
                            "is_intermediate_step": True
                        }
                    }
                    
                    # è¾“å‡ºè§‚å¯Ÿç»“æœ
                    obs_info = f"ğŸ“Š ç»“æœ: {observation}\n"
                    yield {
                        "response": obs_info,
                        "metadata": {
                            "query": query,
                            "agent_type": "unified",
                            "session_id": self.session_id,
                            "is_intermediate_step": True
                        }
                    }
                else:
                    # å…¶ä»–æ ¼å¼ï¼Œç›´æ¥è¾“å‡º
                    yield {
                        "response": f"ğŸ”„ {str(step)}\n",
                        "metadata": {
                            "query": query,
                            "agent_type": "unified",
                            "session_id": self.session_id,
                            "is_intermediate_step": True
                        }
                    }
        elif isinstance(chunk, dict) and "messages" in chunk:
            # æ¶ˆæ¯è¾“å‡º
            for message in chunk["messages"]:
                if hasattr(message, "content"):
                    yield {
                        "response": message.content,
                        "metadata": {
                            "query": query,
                            "agent_type": "unified",
                            "session_id": self.session_id,
                            "is_message": True
                        }
                    }
                else:
                    yield {
                        "response": str(message),
                        "metadata": {
                            "query": query,
                            "agent_type": "unified",
                            "session_id": self.session_id,
                            "is_message": True
                        }
                    }
        else:
            # å…¶ä»–ç±»å‹çš„è¾“å‡ºï¼Œå°è¯•ç›´æ¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            yield {
                "response": str(chunk),
                "metadata": {
                    "query": query,
                    "agent_type": "unified",
                    "session_id": self.session_id,
                    "is_raw": True
                }
            }

    def set_output_format(self, format_type: str) -> None:
        """
        è®¾ç½®è¾“å‡ºæ ¼å¼
        
        Args:
            format_type: è¾“å‡ºæ ¼å¼ç±»å‹ (normal, markdown, json)
        """
        self.output_formatter.set_format(format_type)
    
    def get_output_format(self) -> str:
        """
        è·å–å½“å‰è¾“å‡ºæ ¼å¼
        
        Returns:
            å½“å‰è¾“å‡ºæ ¼å¼ç±»å‹
        """
        return self.output_formatter.get_format()
    
    def clear_memory(self) -> None:
        """æ¸…é™¤è®°å¿†"""
        if self.memory:
            self.memory.clear()
            print("âœ… å¯¹è¯å†å²å·²æ¸…é™¤")
    
    def get_memory(self) -> List[BaseMessage]:
        """
        è·å–è®°å¿†å†…å®¹
        
        Returns:
            è®°å¿†æ¶ˆæ¯åˆ—è¡¨
        """
        if self.memory:
            return self.memory.messages
        return []
    
    def get_summary_history(self) -> List[str]:
        """
        è·å–å¯¹è¯æ‘˜è¦å†å²
        
        Returns:
            æ‘˜è¦å†å²åˆ—è¡¨
        """
        if self.memory and hasattr(self.memory, 'get_summary_history'):
            return self.memory.get_summary_history()
        return []
    
    def get_memory_stats(self) -> Dict[str, Any]:
        """
        è·å–è®°å¿†ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            è®°å¿†ç»Ÿè®¡å­—å…¸
        """
        if not self.memory:
            return {
                "enabled": False,
                "message_count": 0,
                "summary_count": 0
            }
        
        from langchain_core.messages import HumanMessage as HumanMsg
        
        messages = self.memory.messages
        summaries = self.get_summary_history()
        
        return {
            "enabled": True,
            "message_count": len(messages),
            "summary_count": len(summaries),
            "conversation_rounds": len([m for m in messages if isinstance(m, HumanMsg)]),
            "memory_type": "redis" if self.redis_url else "in_memory_with_summary",
            "session_id": self.session_id
        }
    
    def get_session_info(self) -> Dict[str, Any]:
        """
        è·å–ä¼šè¯ä¿¡æ¯
        
        Returns:
            ä¼šè¯ä¿¡æ¯å­—å…¸
        """
        info = {
            "session_id": self.session_id,
            "has_memory": self.memory is not None,
            "memory_type": "redis" if self.redis_url else "in_memory",
            "output_format": self.output_formatter.get_format(),
            "tools_count": len(self.tools)
        }
        
        # å¦‚æœä½¿ç”¨Rediså­˜å‚¨ï¼Œè·å–é¢å¤–ä¿¡æ¯
        if self.redis_url and self.memory:
            try:
                redis_info = self.memory.get_session_info()
                info.update(redis_info)
            except Exception as e:
                info["redis_error"] = str(e)
        
        return info
    
    # ğŸ†• è‡ªåŠ¨ç»§ç»­æ‰§è¡Œç›¸å…³æ–¹æ³•
    
    def _detect_stop_reason(self, response: Dict[str, Any], error: Optional[Exception] = None) -> AgentStopReason:
        """
        æ£€æµ‹æ™ºèƒ½ä½“åœæ­¢åŸå› 
        
        Args:
            response: æ‰§è¡Œå“åº”
            error: å¼‚å¸¸å¯¹è±¡ï¼ˆå¦‚æœæœ‰ï¼‰
        
        Returns:
            åœæ­¢åŸå› 
        """
        if error:
            return AgentStopReason.ERROR
        
        # æ£€æŸ¥å“åº”ä¸­çš„å…ƒæ•°æ®
        if isinstance(response, dict):
            metadata = response.get("metadata", {})
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°è¿­ä»£é™åˆ¶
            if "iteration_limit_reached" in str(response).lower():
                return AgentStopReason.ITERATION_LIMIT
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ—¶é—´é™åˆ¶
            if "time_limit" in str(response).lower() or "timeout" in str(response).lower():
                return AgentStopReason.TIME_LIMIT
            
            # æ£€æŸ¥è¾“å‡ºæ˜¯å¦åŒ…å«å®Œæ•´ç»“æœ
            output = response.get("output", "")
            if output and "Final Answer" in str(output):
                return AgentStopReason.COMPLETED
        
        # é»˜è®¤è®¤ä¸ºä»»åŠ¡å®Œæˆ
        return AgentStopReason.COMPLETED
    
    def _generate_continuation_prompt(self, original_query: str, previous_results: List[str], last_actions: List[str]) -> str:
        """
        ç”Ÿæˆç»§ç»­æ‰§è¡Œçš„æç¤º
        
        Args:
            original_query: åŸå§‹æŸ¥è¯¢
            previous_results: ä¹‹å‰çš„ç»“æœåˆ—è¡¨
            last_actions: æœ€åå‡ æ­¥çš„åŠ¨ä½œ
        
        Returns:
            ç»§ç»­æ‰§è¡Œçš„æç¤º
        """
        # æ„å»ºä¸Šä¸‹æ–‡æ‘˜è¦
        context = f"""åŸå§‹ä»»åŠ¡: {original_query}

å·²å®Œæˆçš„å·¥ä½œ:
"""
        for i, result in enumerate(previous_results, 1):
            result_summary = result[:200] + "..." if len(result) > 200 else result
            context += f"{i}. {result_summary}\n"
        
        if last_actions:
            context += f"\næœ€è¿‘çš„æ“ä½œ:\n"
            for action in last_actions:
                context += f"- {action}\n"
        
        context += f"""

è¯·ç»§ç»­å®Œæˆä»»åŠ¡ï¼ŒåŸºäºä»¥ä¸Šå·²å®Œæˆçš„å·¥ä½œã€‚ä¸è¦é‡å¤å·²å®Œæˆçš„æ­¥éª¤ã€‚"""
        
        return context
    
    def _extract_last_actions(self, response: Dict[str, Any], n: int = 3) -> List[str]:
        """
        æå–æœ€å n ä¸ªåŠ¨ä½œ
        
        Args:
            response: æ‰§è¡Œå“åº”
            n: æå–æ•°é‡
        
        Returns:
            åŠ¨ä½œåˆ—è¡¨
        """
        actions = []
        if isinstance(response, dict):
            intermediate_steps = response.get("intermediate_steps", [])
            for step in intermediate_steps[-n:]:
                if len(step) >= 2:
                    action, observation = step[0], step[1]
                    if hasattr(action, 'tool') and hasattr(action, 'tool_input'):
                        actions.append(f"{action.tool}: {str(action.tool_input)[:100]}")
        return actions
    
    def run_with_auto_continue(
        self, 
        query: str, 
        session_id: str = "default",
        max_retries: int = 3,
        reset_iterations: bool = True
    ) -> Dict[str, Any]:
        """
        è¿è¡Œæ™ºèƒ½ä½“ï¼Œæ”¯æŒè‡ªåŠ¨ç»§ç»­æ‰§è¡Œ
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            session_id: ä¼šè¯ID
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            reset_iterations: æ˜¯å¦åœ¨æ¯æ¬¡é‡è¯•æ—¶é‡ç½®è¿­ä»£è®¡æ•°
        
        Returns:
            åŒ…å«å“åº”å’Œå…ƒæ•°æ®çš„å­—å…¸
        """
        original_query = query
        accumulated_results = []
        total_iterations = 0
        
        for attempt in range(max_retries + 1):
            try:
                if self.streaming_style != "none" and attempt > 0:
                    print(f"\nğŸ”„ è‡ªåŠ¨ç»§ç»­æ‰§è¡Œ ({attempt}/{max_retries})...")
                
                # å¦‚æœä¸æ˜¯ç¬¬ä¸€æ¬¡å°è¯•ï¼Œç”Ÿæˆç»­æ¥æç¤º
                if attempt > 0:
                    last_actions = self._extract_last_actions(result, n=3) if 'result' in locals() else []
                    query = self._generate_continuation_prompt(
                        original_query,
                        accumulated_results,
                        last_actions
                    )
                
                # æ‰§è¡Œæ™ºèƒ½ä½“
                result = self.run(query, session_id)
                
                # æ£€æµ‹åœæ­¢åŸå› 
                stop_reason = self._detect_stop_reason(result)
                
                # ç´¯ç§¯ç»“æœ
                if result.get("response"):
                    accumulated_results.append(result["response"])
                
                # å¦‚æœä»»åŠ¡å®Œæˆï¼Œè¿”å›ç»“æœ
                if stop_reason == AgentStopReason.COMPLETED:
                    if self.streaming_style != "none" and attempt > 0:
                        print(f"âœ… ä»»åŠ¡å®Œæˆï¼ˆç»è¿‡ {attempt + 1} æ¬¡æ‰§è¡Œï¼‰")
                    
                    # åˆå¹¶æ‰€æœ‰ç»“æœ
                    final_response = "\n\n".join(accumulated_results)
                    result["response"] = final_response
                    result["metadata"]["auto_continue_attempts"] = attempt + 1
                    result["metadata"]["stop_reason"] = stop_reason.value
                    return result
                
                # å¦‚æœæ˜¯é”™è¯¯ï¼Œä¸å†ç»§ç»­
                if stop_reason == AgentStopReason.ERROR:
                    result["metadata"]["stop_reason"] = stop_reason.value
                    return result
                
                # å¦‚æœè¾¾åˆ°é‡è¯•æ¬¡æ•°ï¼Œè¿”å›å½“å‰ç»“æœ
                if attempt >= max_retries:
                    if self.streaming_style != "none":
                        print(f"âš ï¸  è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})ï¼Œè¿”å›éƒ¨åˆ†ç»“æœ")
                    final_response = "\n\n".join(accumulated_results)
                    result["response"] = final_response
                    result["metadata"]["auto_continue_attempts"] = attempt + 1
                    result["metadata"]["stop_reason"] = stop_reason.value
                    result["metadata"]["partial_result"] = True
                    return result
                
            except Exception as e:
                error_result = {
                    "response": f"æ‰§è¡Œå‡ºé”™: {str(e)}",
                    "metadata": {
                        "error": str(e),
                        "auto_continue_attempts": attempt + 1,
                        "stop_reason": AgentStopReason.ERROR.value
                    }
                }
                return error_result
        
        # ä¸åº”è¯¥åˆ°è¾¾è¿™é‡Œ
        return {
            "response": "æœªçŸ¥é”™è¯¯",
            "metadata": {"error": "æœªçŸ¥é”™è¯¯"}
        }