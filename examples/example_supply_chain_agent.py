#!/usr/bin/env python3
"""
ä¾›åº”é“¾æ™ºèƒ½ä½“ç¤ºä¾‹

è¿™ä¸ªç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨SupplyChainAgentè¿›è¡Œä¾›åº”é“¾ä¸šåŠ¡æµç¨‹è§„åˆ’ã€ç¡®è®¤å’ŒCrewAIé…ç½®ç”Ÿæˆã€‚
"""

import os
import asyncio
import json
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å¯¼å…¥ä¾›åº”é“¾æ™ºèƒ½ä½“å’Œç›¸å…³å·¥å…·
from src.agents.supply_chain.supply_chain_agent import SupplyChainAgent
from src.infrastructure.llm.llm_factory import LLMFactory


async def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºLLMå®ä¾‹
    llm = LLMFactory.create_llm(
        provider="openai",  # å¯ä»¥æ˜¯ "openai", "anthropic", "huggingface"
        model_name="gpt-3.5-turbo",
        temperature=0.7,
        max_tokens=2000
    )
    
    # åˆ›å»ºä¾›åº”é“¾æ™ºèƒ½ä½“
    try:
        # å°è¯•ä½¿ç”¨Rediså­˜å‚¨
        agent = SupplyChainAgent(
            llm=llm,
            redis_url="redis://localhost:6379/0",
            session_id="supply_chain_demo",
            verbose=True
        )
        print("âœ… ä¾›åº”é“¾æ™ºèƒ½ä½“åˆ›å»ºæˆåŠŸï¼Œä½¿ç”¨Rediså­˜å‚¨")
    except ConnectionError as e:
        print(f"âš ï¸ Redisè¿æ¥å¤±è´¥: {e}")
        print("ğŸ”„ å›é€€åˆ°å†…å­˜å­˜å‚¨æ¨¡å¼")
        
        # åˆ›å»ºä¸å¸¦Redisçš„æ™ºèƒ½ä½“
        agent = SupplyChainAgent(
            llm=llm,
            redis_url=None,
            session_id="supply_chain_demo",
            verbose=True
        )
        print("âœ… ä¾›åº”é“¾æ™ºèƒ½ä½“åˆ›å»ºæˆåŠŸï¼Œä½¿ç”¨å†…å­˜å­˜å‚¨")
    
    # ç¤ºä¾‹1: ä¸šåŠ¡æµç¨‹è§„åˆ’
    print("=" * 50)
    print("ç¤ºä¾‹1: ä¸šåŠ¡æµç¨‹è§„åˆ’")
    print("=" * 50)
    
    user_input = "æˆ‘éœ€è¦ä¼˜åŒ–å…¬å¸çš„é‡‡è´­æµç¨‹ï¼Œç›®å‰é‡‡è´­å‘¨æœŸé•¿ã€æˆæœ¬é«˜ï¼Œå¸Œæœ›èƒ½ç¼©çŸ­é‡‡è´­å‘¨æœŸ30%ï¼Œé™ä½æˆæœ¬15%"
    response = await agent.chat(user_input)
    print(f"ç”¨æˆ·: {user_input}")
    print(f"æ™ºèƒ½ä½“: {response}")
    print()
    
    # ç¤ºä¾‹2: ç¡®è®¤æµç¨‹è§„åˆ’
    print("=" * 50)
    print("ç¤ºä¾‹2: ç¡®è®¤æµç¨‹è§„åˆ’")
    print("=" * 50)
    
    user_input = "ç¡®è®¤"
    response = await agent.chat(user_input)
    print(f"ç”¨æˆ·: {user_input}")
    print(f"æ™ºèƒ½ä½“: {response}")
    print()
    
    # ç¤ºä¾‹3: è·å–ä¼šè¯ä¿¡æ¯
    print("=" * 50)
    print("ç¤ºä¾‹3: è·å–ä¼šè¯ä¿¡æ¯")
    print("=" * 50)
    
    session_info = agent.get_session_info()
    print(f"ä¼šè¯ä¿¡æ¯: {json.dumps(session_info, indent=2, ensure_ascii=False)}")
    print()
    
    # ç¤ºä¾‹4: æµå¼è¾“å‡º
    print("=" * 50)
    print("ç¤ºä¾‹4: æµå¼è¾“å‡º")
    print("=" * 50)
    
    user_input = "å¦‚ä½•è¿›è¡Œä¾›åº”å•†è¯„ä¼°ä¸åˆ†ç±»ï¼Ÿ"
    print(f"ç”¨æˆ·: {user_input}")
    print("æ™ºèƒ½ä½“: ", end="", flush=True)
    
    async for chunk in agent.stream(user_input):
        print(chunk, end="", flush=True)
    print("\n")
    
    # ç¤ºä¾‹5: è¿è¡Œæ™ºèƒ½ä½“ï¼ˆè·å–å®Œæ•´ç»“æœï¼‰
    print("=" * 50)
    print("ç¤ºä¾‹5: è¿è¡Œæ™ºèƒ½ä½“ï¼ˆè·å–å®Œæ•´ç»“æœï¼‰")
    print("=" * 50)
    
    user_input = "è¯·ç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„ä¾›åº”é“¾ä¼˜åŒ–æ–¹æ¡ˆï¼ŒåŒ…æ‹¬åº“å­˜ç®¡ç†å’Œç‰©æµé…é€ä¼˜åŒ–"
    result = await agent.run(user_input)
    
    print(f"ç”¨æˆ·: {user_input}")
    print(f"æ™ºèƒ½ä½“: {result['response']}")
    print(f"å…ƒæ•°æ®: {json.dumps(result['metadata'], indent=2, ensure_ascii=False)}")
    print()
    
    # ç¤ºä¾‹6: é‡ç½®ä¼šè¯
    print("=" * 50)
    print("ç¤ºä¾‹6: é‡ç½®ä¼šè¯")
    print("=" * 50)
    
    agent.reset_session()
    print("ä¼šè¯å·²é‡ç½®")
    
    session_info = agent.get_session_info()
    print(f"é‡ç½®åçš„ä¼šè¯ä¿¡æ¯: {json.dumps(session_info, indent=2, ensure_ascii=False)}")


if __name__ == "__main__":
    asyncio.run(main())