#!/usr/bin/env python3
"""
ä¸»ç¨‹åºå…¥å£æ–‡ä»¶
"""

import os
import sys
import warnings
import argparse
import logging
from typing import Optional

# åŠ è½½ .env æ–‡ä»¶
from dotenv import load_dotenv
load_dotenv()

# åœ¨å¯¼å…¥LangChainä¹‹å‰è®¾ç½®ç¯å¢ƒå˜é‡æ¥æŠ‘åˆ¶å¼ƒç”¨è­¦å‘Š
os.environ["PYTHONWARNINGS"] = "ignore::DeprecationWarning:langchain.*"
warnings.filterwarnings("ignore", category=DeprecationWarning, module="langchain.*")
warnings.filterwarnings("ignore", message="Please see the migration guide at", category=DeprecationWarning)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

from src.agents.unified.unified_agent import UnifiedAgent
from src.config.config_loader import config_loader


def setup_logging(debug_mode=False):
    """è®¾ç½®æ—¥å¿—"""
    # å®Œå…¨ç¦ç”¨æ‰€æœ‰å¼ƒç”¨è­¦å‘Š
    warnings.filterwarnings("ignore", category=DeprecationWarning)
    warnings.filterwarnings("ignore", message="Please see the migration guide at")
    
    # éè°ƒè¯•æ¨¡å¼ä¸‹ï¼Œè¿‡æ»¤å„ç§è­¦å‘Š
    if not debug_mode:
        warnings.filterwarnings("ignore", category=UserWarning, message=".*API key must be provided when hosted LangSmith API.*")
        warnings.filterwarnings("ignore", category=UserWarning, message=".*CrewAIæ‰§è¡Œè¿‡ç¨‹.*")
        # è¿‡æ»¤LangChainå‚æ•°è­¦å‘Š
        warnings.filterwarnings("ignore", message=".*is not default parameter.*")
        warnings.filterwarnings("ignore", message=".*was transferred to model_kwargs.*")
    
    logging_config = config_loader.get_logging_config()
    # åœ¨debugæ¨¡å¼ä¸‹ï¼Œå°†æ—¥å¿—çº§åˆ«è®¾ç½®ä¸ºDEBUG
    if debug_mode:
        level = logging.DEBUG
    else:
        level = logging.INFO  # édebugæ¨¡å¼åªæ˜¾ç¤ºINFOåŠä»¥ä¸Šçº§åˆ«çš„æ—¥å¿—
    
    format_str = logging_config.get("format", "%(asctime)s - %(name)s - %(levelname)s - %(message)s")
    log_file = logging_config.get("file", "logs/agent.log")
    
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    os.makedirs(os.path.dirname(log_file), exist_ok=True)
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=level,
        format=format_str,
        handlers=[
            logging.FileHandler(log_file),
            logging.StreamHandler()
        ]
    )
    
    # è·å–è°ƒè¯•é…ç½®
    debug_config = logging_config.get("debug", {})
    
    # è®¾ç½®è°ƒè¯•è¿‡æ»¤å™¨
    from src.shared.debug_filter import setup_debug_filters
    setup_debug_filters(debug_mode, debug_config)
    
    # éè°ƒè¯•æ¨¡å¼ä¸‹ï¼Œæé«˜ç¬¬ä¸‰æ–¹åº“çš„æ—¥å¿—çº§åˆ«ï¼Œåªæ˜¾ç¤ºERRORåŠä»¥ä¸Š
    if not debug_mode:
        logging.getLogger("langchain_community").setLevel(logging.ERROR)
        logging.getLogger("openai").setLevel(logging.ERROR)
        logging.getLogger("httpx").setLevel(logging.ERROR)
        logging.getLogger("httpcore").setLevel(logging.ERROR)
        logging.getLogger("langsmith").setLevel(logging.ERROR)


def interactive_mode(agent: UnifiedAgent, stream: bool = False):
    """äº¤äº’æ¨¡å¼"""
    print("=== LangChainæ™ºèƒ½ä½“äº¤äº’æ¨¡å¼ ===")
    print("è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
    print("è¾“å…¥ 'clear' æ¸…é™¤å¯¹è¯å†å²")
    print("è¾“å…¥ 'memory' æŸ¥çœ‹å¯¹è¯å†å²")
    print("è¾“å…¥ 'stats' æŸ¥çœ‹è®°å¿†ç»Ÿè®¡")
    print("è¾“å…¥ 'summary' æŸ¥çœ‹å¯¹è¯æ‘˜è¦")
    print("=" * 40)
    
    while True:
        try:
            user_input = input("\næ‚¨: ").strip()
            
            if user_input.lower() in ['quit', 'exit']:
                print("å†è§!")
                break
            elif user_input.lower() == 'clear':
                agent.clear_memory()
                print("å¯¹è¯å†å²å·²æ¸…é™¤")
                continue
            elif user_input.lower() == 'memory':
                memory = agent.get_memory()
                if memory:
                    print("\n=== å¯¹è¯å†å² ===")
                    for i, msg in enumerate(memory):
                        msg_type = "ç”¨æˆ·" if msg.type == "human" else "åŠ©æ‰‹"
                        content = msg.content[:100] + "..." if len(msg.content) > 100 else msg.content
                        print(f"{msg_type}: {content}")
                    print("=" * 40)
                else:
                    print("æš‚æ— å¯¹è¯å†å²")
                continue
            elif user_input.lower() == 'stats':
                stats = agent.get_memory_stats()
                print("\n=== è®°å¿†ç»Ÿè®¡ ===")
                print(f"è®°å¿†çŠ¶æ€: {'å¯ç”¨' if stats['enabled'] else 'æœªå¯ç”¨'}")
                print(f"æ¶ˆæ¯æ•°é‡: {stats['message_count']}")
                print(f"å¯¹è¯è½®æ•°: {stats.get('conversation_rounds', 0)}")
                print(f"æ‘˜è¦æ•°é‡: {stats['summary_count']}")
                print(f"å­˜å‚¨ç±»å‹: {stats.get('memory_type', 'unknown')}")
                print(f"ä¼šè¯ID: {stats.get('session_id', 'unknown')}")
                print("=" * 40)
                continue
            elif user_input.lower() == 'summary':
                summaries = agent.get_summary_history()
                if summaries:
                    print("\n=== å¯¹è¯æ‘˜è¦å†å² ===")
                    for i, summary in enumerate(summaries, 1):
                        print(f"\næ‘˜è¦ {i}:")
                        print(summary)
                    print("\n" + "=" * 40)
                else:
                    print("æš‚æ— å¯¹è¯æ‘˜è¦ï¼ˆå¯¹è¯è½®æ•°è¾ƒå°‘ï¼Œæœªè§¦å‘è‡ªåŠ¨æ‘˜è¦ï¼‰")
                continue
            
            # æ³¨æ„ï¼šstreaming_style å‚æ•°å·²ç»åœ¨åˆ›å»ºagentæ—¶è®¾ç½®äº†callbacks
            # è¿™äº›callbacksä¼šåœ¨run()æ–¹æ³•æ‰§è¡Œæ—¶è‡ªåŠ¨è§¦å‘ï¼Œæä¾›å®æ—¶è¾“å‡º
            # æ‰€ä»¥è¿™é‡Œç»Ÿä¸€ä½¿ç”¨run()æ–¹æ³•ï¼Œä¸éœ€è¦åŒºåˆ†streamå‚æ•°
            response = agent.run(user_input)
            if isinstance(response, dict) and "response" in response:
                print(f"\nåŠ©æ‰‹: {response['response']}")
            else:
                print(f"\nåŠ©æ‰‹: {response}")
            
        except KeyboardInterrupt:
            print("\n\nç¨‹åºè¢«ä¸­æ–­ï¼Œå†è§!")
            break
        except EOFError:
            # å¤„ç†EOFé”™è¯¯ï¼ˆä¾‹å¦‚ç®¡é“è¾“å…¥ç»“æŸï¼‰
            print("\n\nè¾“å…¥ç»“æŸï¼Œå†è§!")
            break
        except Exception as e:
            print(f"\né”™è¯¯: {str(e)}")


def single_query_mode(agent: UnifiedAgent, query: str, stream: bool = False, auto_continue: bool = False, max_retries: int = 3):
    """å•æ¬¡æŸ¥è¯¢æ¨¡å¼"""
    try:
        # æ³¨æ„ï¼šstreaming_style å‚æ•°å·²ç»åœ¨åˆ›å»ºagentæ—¶è®¾ç½®äº†callbacks
        # è¿™äº›callbacksä¼šåœ¨run()æ–¹æ³•æ‰§è¡Œæ—¶è‡ªåŠ¨è§¦å‘ï¼Œæä¾›å®æ—¶è¾“å‡º
        
        # ğŸ†• å¦‚æœå¯ç”¨è‡ªåŠ¨ç»§ç»­ï¼Œä½¿ç”¨ run_with_auto_continue
        if auto_continue:
            print(f"ğŸ”„ è‡ªåŠ¨ç»§ç»­æ¨¡å¼å·²å¯ç”¨ï¼ˆæœ€å¤§é‡è¯•: {max_retries}ï¼‰")
            response = agent.run_with_auto_continue(query, max_retries=max_retries)
        else:
            response = agent.run(query)
        
        if isinstance(response, dict) and "response" in response:
            print(f"\n{response['response']}")
            # ğŸ†• æ˜¾ç¤ºè‡ªåŠ¨ç»§ç»­çš„ç»Ÿè®¡ä¿¡æ¯
            if auto_continue and "metadata" in response:
                attempts = response["metadata"].get("auto_continue_attempts", 1)
                if attempts > 1:
                    print(f"\nğŸ“Š ç»Ÿè®¡: ç»è¿‡ {attempts} æ¬¡æ‰§è¡Œå®Œæˆä»»åŠ¡")
        else:
            print(f"\n{response}")
    except Exception as e:
        print(f"é”™è¯¯: {str(e)}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ™ºèƒ½ä½“ç³»ç»Ÿ")
    parser.add_argument("--provider", choices=["openai", "anthropic", "ollama", "siliconflow"], default="siliconflow", help="é€‰æ‹©LLMæä¾›å•†")
    parser.add_argument("--query", type=str, help="å•æ¬¡æŸ¥è¯¢æ¨¡å¼")
    parser.add_argument("--interactive", action="store_true", help="äº¤äº’æ¨¡å¼")
    parser.add_argument("--stream", "-s", action="store_true", help="å¯ç”¨æµå¼è¾“å‡º")
    parser.add_argument("--streaming-style", choices=["simple", "detailed", "none"], default="simple", 
                       help="æµå¼è¾“å‡ºæ ·å¼: simple=ç®€æ´ç¾è§‚, detailed=è¯¦ç»†å®Œæ•´, none=åªæ˜¾ç¤ºç»“æœ")
    parser.add_argument("--auto-continue", action="store_true", help="ğŸ†• å¯ç”¨è‡ªåŠ¨ç»§ç»­æ‰§è¡Œï¼ˆè¾¾åˆ°é™åˆ¶æ—¶è‡ªåŠ¨ç»­æ¥ï¼‰")
    parser.add_argument("--max-retries", type=int, default=3, help="ğŸ†• è‡ªåŠ¨ç»§ç»­çš„æœ€å¤§é‡è¯•æ¬¡æ•°")
    parser.add_argument("--config", type=str, help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--debug", action="store_true", help="è°ƒè¯•æ¨¡å¼ï¼Œæ˜¾ç¤ºè¯¦ç»†æ—¥å¿—")
    parser.add_argument("--no-debug", action="store_true", help="å…³é—­è°ƒè¯•æ¨¡å¼ï¼Œä»…æ˜¾ç¤ºå¯¹è¯ä¿¡æ¯")
    
    args = parser.parse_args()
    
    # å¦‚æœæŒ‡å®šäº†é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé‡æ–°åŠ è½½é…ç½®
    if args.config:
        global config_loader
        from src.config.config_loader import ConfigLoader
        config_loader = ConfigLoader(args.config)
    
    # è®¾ç½®æ—¥å¿—
    debug_mode = args.debug and not args.no_debug
    setup_logging(debug_mode)
    
    try:
        # åˆ›å»ºæ™ºèƒ½ä½“ï¼ˆä¼ å…¥streaming_styleå‚æ•°ï¼‰
        agent = UnifiedAgent(
            provider=args.provider,
            streaming_style=args.streaming_style
        )
        
        if args.query:
            # å•æ¬¡æŸ¥è¯¢æ¨¡å¼
            # ğŸ†• ä¼ é€’auto_continueå’Œmax_retrieså‚æ•°
            single_query_mode(agent, args.query, args.stream, args.auto_continue, args.max_retries)
        elif args.interactive:
            interactive_mode(agent, args.stream)
        else:
            interactive_mode(agent, args.stream)
    
    except Exception as e:
        print(f"åˆå§‹åŒ–æ™ºèƒ½ä½“å¤±è´¥: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main()